{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom torchvision.io import read_image, ImageReadMode\nfrom torchvision.transforms import v2\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n    break\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-16T05:55:00.127557Z","iopub.execute_input":"2024-06-16T05:55:00.128460Z","iopub.status.idle":"2024-06-16T05:55:08.490206Z","shell.execute_reply.started":"2024-06-16T05:55:00.128426Z","shell.execute_reply":"2024-06-16T05:55:08.489397Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Pre-processing\nNORMAL = 0\nPNEUMONIA = 1\n# transforms = v2.Compose([\n#                  v2.ToImage(),  # Convert to tensor, only needed if you had a PIL image\n#                  v2.ToDtype(torch.uint8, scale=True),  # optional, most input are already uint8 at this point\n#                  # v2.RandomResizedCrop(size=(256, 256), antialias=True),  # Or Resize(antialias=True)\n#                  v2.ToDtype(torch.float32, scale=True),  # Normalize expects float input\n#                  v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n#                  ])\ntransforms = v2.Compose([\n#                     v2.Resize((512, 512))\n                    v2.Resize((128, 128)),\n                    v2.Grayscale(num_output_channels=3),\n                    v2.ToTensor()\n#                     v2.Resize((32, 32))\n#                     v2.RandomResizedCrop((32, 12832\n                    ])\npath = '/kaggle/input/chest-xray-pneumonia/chest_xray/train/'\ndef make_dataframe(dataset_name):\n    normal_path = f'/kaggle/input/chest-xray-pneumonia/chest_xray/{dataset_name}/NORMAL'\n    pneumonia_path = f'/kaggle/input/chest-xray-pneumonia/chest_xray/{dataset_name}/PNEUMONIA'\n    X = []\n    Y = []\n    with os.scandir(normal_path) as it:\n        for entry in it:\n            X.append(entry.path)\n            Y.append(NORMAL)\n\n    with os.scandir(pneumonia_path) as it:\n        for entry in it:\n            X.append(entry.path)\n            Y.append(PNEUMONIA)\n\n    data = {'image': X, 'label': Y}\n    df = pd.DataFrame(data)\n    return df\n\ntest_df = make_dataframe('test')\ntrain_df = make_dataframe('train')\nval_df = make_dataframe('val')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:55:08.491976Z","iopub.execute_input":"2024-06-16T05:55:08.492570Z","iopub.status.idle":"2024-06-16T05:55:09.381934Z","shell.execute_reply.started":"2024-06-16T05:55:08.492535Z","shell.execute_reply":"2024-06-16T05:55:09.381109Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, dataframe, transform=None, target_transform=None):\n        self.img_labels = dataframe['label']\n        self.img_paths = dataframe['image']\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = self.img_paths.iloc[idx]\n        image = read_image(img_path, ImageReadMode.RGB).to('cuda')\n        label = self.img_labels.iloc[idx]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:55:09.382986Z","iopub.execute_input":"2024-06-16T05:55:09.383253Z","iopub.status.idle":"2024-06-16T05:55:09.390313Z","shell.execute_reply.started":"2024-06-16T05:55:09.383229Z","shell.execute_reply":"2024-06-16T05:55:09.389371Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def show_image(tensor):\n    arr_ = np.squeeze(tensor)\n    plt.imshow(arr_, cmap='gray')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:55:18.065453Z","iopub.execute_input":"2024-06-16T05:55:18.066031Z","iopub.status.idle":"2024-06-16T05:55:18.070284Z","shell.execute_reply.started":"2024-06-16T05:55:18.065997Z","shell.execute_reply":"2024-06-16T05:55:18.069467Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"test_dataset = CustomImageDataset(test_df, transform=transforms)\ntrain_dataset = CustomImageDataset(train_df, transform=transforms)\nval_dataset = CustomImageDataset(val_df, transform=transforms)\n# tensor = train_dataset.__getitem__(20)[0]\n# show_image(tensor.to('cpu'))\n# train_dataset.__getitem__(39)[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:55:28.498293Z","iopub.execute_input":"2024-06-16T05:55:28.498738Z","iopub.status.idle":"2024-06-16T05:55:28.511477Z","shell.execute_reply.started":"2024-06-16T05:55:28.498702Z","shell.execute_reply":"2024-06-16T05:55:28.510379Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\n\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:55:29.750175Z","iopub.execute_input":"2024-06-16T05:55:29.750604Z","iopub.status.idle":"2024-06-16T05:55:29.757698Z","shell.execute_reply.started":"2024-06-16T05:55:29.750567Z","shell.execute_reply":"2024-06-16T05:55:29.756531Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self, batch_size):\n        super().__init__()\n#         self.conv1 = nn.Conv2d(1, 16, 258, stride=2)\n#         self.conv2 = nn.Conv2d(16, 32, 2, stride=2)\n#         self.pool1 = nn.AvgPool2d(5, stride=1)\n#         self.conv3 = nn.Conv2d(32, 64, 29)\n#         self.pool2 = nn.MaxPool2d(18, 2)\n#         self.fc1 = nn.Linear(64 * 8 * 8 * batch_size, 1024* batch_size)\n#         self.fc2 = nn.Linear(1024* batch_size, 128* batch_size)\n#         self.fc3 = nn.Linear(128* batch_size, 16* batch_size)\n#         self.fc4 = nn.Linear(16* batch_size, 1* batch_size)\n#         self.conv1 = nn.Conv2d(1, 4, 65)\n#         self.batchnorm1 = nn.BatchNorm2d(4)\n#         self.conv2 = nn.Conv2d(4, 8, 33)\n#         self.batchnorm2 = nn.BatchNorm2d(8)\n#         self.pool1 = nn.AvgPool2d(2, stride=1)\n#         self.conv3 = nn.Conv2d(8, 16, 15)\n#         self.batchnorm3 = nn.BatchNorm2d(16)\n#         self.pool2 = nn.MaxPool2d(2, 2)\n#         self.fc1 = nn.Linear(16 * 8 * 8 * batch_size, 128* batch_size)\n#         self.fc2 = nn.Linear(128* batch_size, 64* batch_size)\n#         self.fc3 = nn.Linear(64* batch_size, 16* batch_size)\n#         self.fc4 = nn.Linear(16* batch_size, 1* batch_size)\n        self.conv1 = nn.Conv2d(1, 8, 2, stride=2)\n        self.conv2 = nn.Conv2d(8, 16, 2, stride=1)\n        self.pool1 = nn.AvgPool2d(2, stride=1)\n        self.conv3 = nn.Conv2d(16, 32, 2)\n        self.pool2 = nn.MaxPool2d(6, stride=1)\n        self.fc1 = nn.Linear(32 * 8 * 8 * batch_size, 512 * batch_size)\n        self.fc2 = nn.Linear(512* batch_size, 64* batch_size)\n        self.fc3 = nn.Linear(64* batch_size, 8* batch_size)\n        self.fc4 = nn.Linear(8* batch_size, 1*batch_size)\n\n    def forward(self, x):\n#         x = self.pool1(F.relu(self.batchnorm2(self.conv2(F.relu(self.batchnorm1(self.conv1(x)))))))\n#         x = self.pool2(F.relu(self.batchnorm3(self.conv3(x))))\n#         x = torch.flatten(x)\n#         x = F.relu(self.fc1(x))\n#         x = F.relu(self.fc2(x))\n#         x = F.relu(self.fc3(x))\n# #         x = F.sigmoid(self.fc4(x))\n#         x = self.fc4(x)\n        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n        x = self.pool2(F.relu(self.conv3(x)))\n#         print(x.shape)\n        x = torch.flatten(x)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n#         x = F.sigmoid(self.fc4(x))\n        x = self.fc4(x)\n        return x\n\n\nnet = Net(batch_size)\nnet.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:55:40.538646Z","iopub.execute_input":"2024-06-16T05:55:40.538988Z","iopub.status.idle":"2024-06-16T05:55:43.746150Z","shell.execute_reply.started":"2024-06-16T05:55:40.538958Z","shell.execute_reply":"2024-06-16T05:55:43.745223Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Net(\n  (conv1): Conv2d(1, 8, kernel_size=(2, 2), stride=(2, 2))\n  (conv2): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))\n  (pool1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n  (conv3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n  (pool2): MaxPool2d(kernel_size=6, stride=1, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=32768, out_features=8192, bias=True)\n  (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n  (fc3): Linear(in_features=1024, out_features=128, bias=True)\n  (fc4): Linear(in_features=128, out_features=16, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from torchvision import models\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef CNN_Model(pretrained=True):\n    model = models.densenet121(pretrained=pretrained) # Returns Defined Densenet model with weights trained on ImageNet\n    num_ftrs = model.classifier.in_features # Get the number of features output from CNN layer\n    model.classifier = nn.Linear(num_ftrs, 1) # Overwrites the Classifier layer with custom defined layer for transfer learning\n    model = model.to('cuda') # Transfer the Model to GPU if available\n    return model\nnet = CNN_Model()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:55:43.747899Z","iopub.execute_input":"2024-06-16T05:55:43.748360Z","iopub.status.idle":"2024-06-16T05:55:44.432601Z","shell.execute_reply.started":"2024-06-16T05:55:43.748326Z","shell.execute_reply":"2024-06-16T05:55:44.431684Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:00<00:00, 122MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(net.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:55:46.255635Z","iopub.execute_input":"2024-06-16T05:55:46.256390Z","iopub.status.idle":"2024-06-16T05:55:46.263584Z","shell.execute_reply.started":"2024-06-16T05:55:46.256358Z","shell.execute_reply":"2024-06-16T05:55:46.262744Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\nelse:\n    print(\"No GPU available. Training will run on CPU.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:55:48.689185Z","iopub.execute_input":"2024-06-16T05:55:48.689598Z","iopub.status.idle":"2024-06-16T05:55:48.695090Z","shell.execute_reply.started":"2024-06-16T05:55:48.689562Z","shell.execute_reply":"2024-06-16T05:55:48.694136Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"GPU: Tesla T4 is available.\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model(loader):\n    epochs = 1000\n    running_loss = 0.0\n    epoch = 0\n    for data in loader:\n        try:\n            if epoch >= epochs:\n                break\n        #     if epoch % 10 == 0:\n        #         print(\"Processed: \" + str(epoch))\n            optimizer.zero_grad()\n            image, target = data\n            # forward + backward + optimize\n            inp = image.type(torch.FloatTensor).to('cuda')\n            label = target.type(torch.FloatTensor).to('cuda').reshape((16,1))\n            outputs = net(inp)\n#             print(outputs)\n        #     print(outputs.|shape)\n        #     print(label.shape)\n            loss = criterion(outputs, label).to('cuda')\n            loss.backward()\n            optimizer.step()\n            # print statistics\n            running_loss += loss.item()\n            if epoch % 100 == 99:    # print every 100 mini-batches\n                print(f'[{epoch + 1}, {epoch + 1:5d}] loss: {running_loss / 2000:.3f}')\n                running_loss = 0.0\n            epoch = epoch + 1\n        except Exception as e:\n            print(\"Error: \" + str(e))\n            print(data[0].shape)\n            break\n\n    print('Finished Training')\n    \nnet.train()\n# for _ in range(3):\ntrain_model(train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:55:49.345954Z","iopub.execute_input":"2024-06-16T05:55:49.346645Z","iopub.status.idle":"2024-06-16T05:57:47.327290Z","shell.execute_reply.started":"2024-06-16T05:55:49.346610Z","shell.execute_reply":"2024-06-16T05:57:47.326397Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[100,   100] loss: 0.012\n[200,   200] loss: 0.005\n[300,   300] loss: 0.004\nFinished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"def test(model, device, loader, dataset):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in loader:\n            data, target = data.type(torch.FloatTensor).to('cuda'), target.type(torch.FloatTensor).to('cuda').reshape((16,1))\n            output = model(data)\n            output = (output >= 0.5).float()\n            test_loss += F.binary_cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n#             print(output, target)\n            correct += output.eq(target.view_as(output)).sum().item()\n\n    test_loss /= len(loader.dataset)\n\n    print('\\n{} set: Accuracy: {}/{} ({:.0f}%)\\n'.format(dataset,\n         correct, len(loader.dataset),\n        100. * correct / len(loader.dataset)))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:57:47.329290Z","iopub.execute_input":"2024-06-16T05:57:47.329936Z","iopub.status.idle":"2024-06-16T05:57:47.337943Z","shell.execute_reply.started":"2024-06-16T05:57:47.329897Z","shell.execute_reply":"2024-06-16T05:57:47.336994Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test(net, 'cuda', train_loader, 'Train')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:58:01.355705Z","iopub.execute_input":"2024-06-16T05:58:01.356279Z","iopub.status.idle":"2024-06-16T05:58:59.082253Z","shell.execute_reply.started":"2024-06-16T05:58:01.356240Z","shell.execute_reply":"2024-06-16T05:58:59.081342Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\nTrain set: Accuracy: 5163/5216 (99%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"test(net, 'cuda', val_loader, 'Val')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:58:59.084119Z","iopub.execute_input":"2024-06-16T05:58:59.084870Z","iopub.status.idle":"2024-06-16T05:58:59.390308Z","shell.execute_reply.started":"2024-06-16T05:58:59.084833Z","shell.execute_reply":"2024-06-16T05:58:59.389379Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nVal set: Accuracy: 13/16 (81%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"test(net, 'cuda', test_loader, 'Test')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:58:59.391591Z","iopub.execute_input":"2024-06-16T05:58:59.391947Z","iopub.status.idle":"2024-06-16T05:59:09.858758Z","shell.execute_reply.started":"2024-06-16T05:58:59.391913Z","shell.execute_reply":"2024-06-16T05:59:09.857771Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\nTest set: Accuracy: 508/624 (81%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}